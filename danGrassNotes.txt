## Let's have a look at graham's files. 

## don't know if we will need the FASTQ files... do I have these somewhere?

## not sure, maybe archived them somewhere... check later. 

## for now, can we get graham's biom table up and running?

cd /home/daniel/Documents/submissions/grass-endophyte-community 

R

## update bioconductor, phyloseq
## install.packages('BiocManager')
## BiocManager::install(version = '3.10') ## necessary?
#install.packages("BiocManager")
#BiocManager::install('phyloseq')

install.packages('spatstat')

library(phyloseq)
library(spatstat)
grass97m <- import_biom('grass_97_wmeta.biom')

dim(grass97m@otu_table)
head(grass97m@tax_table) ## wonder how rigorous the ids are on this.

head(grass97m@sam_data, n=2) ## wonder how rigorous the ids are on this.
## looks good for the moment

## so, big goals here are:

## 1) check trend surfaces of community matrix varation  - can we describe the variation in graham's community matrices
## with a north/sound trend in diversity and dissimilarity. The methods for this would 
## be in the spatial analysis with R book, = RDA of community matrices against a polynomial trend surfaces
## I think I recommended this in place of the original dbmem analysis, if it turns out to be informative. 

## 2) Attempt to quantify the apparent increase in n/s diversity. Means 
## repeating Grahams diversity metrics on the pre-variance-stabilization (pre-deseq), then 
## check to see if there is enough statistical power to build a point pattern model from 
## these.   

## 3) figure out the story of the french flat site, the only place where the two grass host species
## share a lot of endophyte species. What are the shared species? Are they unique to the site? are they 
## interesting, as in maybe one of the species that have been shown to give panicum grass salt and drought 
## tolerance?

## let's start messing around with spatstat.

## can we get x,y data for all sites? should be in our metadata somewhere?

head(sample_data(grass97m@sam_data))

md <- sample_data(grass97m@sam_data)

colnames(md)

md$y_coordinate

md$latitude

tail(md) ## last 7 samples are non-ecological, mock communities etc.

## so 162 - 7 = 155 samples. Each of these samples = 1 plant?  

## graham has 13 populations (6 danthonia and 7 festuca). Each should have 12 samples,
## so 13 x 12 = 156 samples. 

## So looks like one row on the otu table is one plant, probably. 

## but what would make sense as a point on a point pattern analysis?

## I think a "population" makes the most sense here. So an average of 
## biodiversity metrics at each sampling site. 

## what is graham's biodiversity metric? Looks like species richness,
## or number of observations of a species. 

## I would agree with this, because of the abundances issue with illumina reads. 

## so we need graham's rarified species richness data, averaged for each site 
## (and split up by host when necessary)  as our "z" variable. 

## to get ready for this, can we make a point object for our geographical sample sites?

md <- sample_data(grass97m@sam_data)

head(md, n=1)
colnames(md)

md$region

md$site

md$site_nr

length(unique(md$site_nr)) ## 10

table(md$site)

length(unique(md$site)) ## 10

## can we turn these into point pattern objects?

levels(md$region)
unique(md$region)

## assuming we generate a matrix of sites by an average diversity metric. 
## for a moment, let's generate a set of random numbers

fakeDiv <- sample(1:4000, nrow(md))
## add to data 
md$fakeDiv <- fakediv

head(md, n=1)

## okay, so now we want averages of this fake diversity by site?
avgFakeDiv <- tapply(md$fakeDiv, md$site, mean)
## our xy for these are long/lat:
latitude <- tapply(as.numeric(md$latitude), md$site, mean)
levels(as.factor(md$latitude))
## that made some weird numbers?

latitude <- tapply(as.numeric(md$latitude), md$site, identity)
## ah - Hazel_Dell has two latitudes, 44.03 and 44.02

md$site

md[md$site=="Hazel_Dell",]

md[md$site=="Hazel_Dell",]$latitude

md[md$site=="Hazel_Dell",]$host

tapply(md[md$site=="Hazel_Dell",]$latitude, md[md$site=="Hazel_Dell",]$host, identity)

## D. californica is at 44.02, F. roemeri at 44.03

## so what do want to do here? we want a table where each site is given an xy and a diversity value.
## so we need to split up the hazel_dell site by host. Let's just do this for all sites, while we're
## at it, because we're going to need to do this anyway...

## this will be a collation of host and site columns:

aa <- md[md$site!="Control",c('host','site','longitude','latitude','fakeDiv')]
aa$longitude <- as.numeric(aa$longitude)
aa$latitude <- as.numeric(aa$latitude)

## plyr might work best here...
library(plyr)

## remind me how this works...
dd<-data.frame(matrix(rnorm(216),72,3),c(rep("A",24),rep("B",24),rep("C",24)),c(rep("J",36),rep("K",36)))
colnames(dd) <- c("v1", "v2", "v3", "dim1", "dim2")
ddply(dd, c("dim1","dim2"), function(df)mean(df$v1))
ddply(dd, c("dim1","dim2"), function(df)c(mean(df$v1),mean(df$v2),mean(df$v3),sd(df$v1),sd(df$v2),sd(df$v3)))

## so for our data....

bb <- ddply(aa, c("site","host"), function(df)c(mean(df$longitude), mean(df$latitude), mean(df$fakeDiv)))
colnames(bb) <- c("site","host", "longitude", "latitude", "fakeDiv")

head(bb)

## can we convert to UTMS?

## in BASH 
sudo apt install libgdal-dev

## back in R
install.packages('rgdal')
## use sp package:
install.packages('sp')

## start over. Here is the pipeline so far:

## we're in UTM zone 10

library(phyloseq)
library(spatstat)
library(sp)
library(plyr)

grass97m <- import_biom('grass_97_wmeta.biom')
md <- sample_data(grass97m@sam_data)
fakeDiv <- sample(1:4000, nrow(md))
md$fakeDiv <- fakeDiv
aa <- md[md$site!="Control",c('host','site','longitude','latitude','fakeDiv')]
aa$longitude <- as.numeric(aa$longitude)
aa$latitude <- as.numeric(aa$latitude)
bb <- ddply(aa, c("site","host"), function(df)c(mean(df$longitude), mean(df$latitude), mean(df$fakeDiv)))
colnames(bb) <- c("site","host", "longitude", "latitude", "fakeDiv")
latlong = SpatialPoints(cbind(bb$longitude, bb$latitude), proj4string=CRS("+proj=longlat"))
UTMs <- spTransform(latlong, CRS("+init=epsg:26910")) ## epsg code for zone 10
UTMs <- data.frame(UTMs) 
bb$x <- UTMs[,1]
bb$y <- UTMs[,2]
## sort by 

## can we make a spatstat object out of this?
## our marks are fakeDiv


cc <- ppp(x=bb$x,y=bb$y, 
        xrange=c(min(bb$x),max(bb$x)), 
        yrange=c(min(bb$y),max(bb$y)), 
        marks=bb$fakeDiv
        )

plot(cc, use.marks=FALSE)

plot(Smooth.ppp(cc))

## looks okay. And if we want to build a model? This is confusing...

## basically we want to test if there is significant north/south 
## trend in these points, in a way that accounts for possible 
## spatial autocorrelation.

## but autocorrelation is only really meaningful if you have 
## some kind of predictor besides distance, and you want to 
## somehow quantify the effect of distance on the system, as a
## source of error. 

## so is it appropriate here to just run a regression with distance?

## then if we are interested in other environmental effects, we 
## can figure out autocorrelation at that point, as a source of error. 

## which means that this just sort of boils down to a trend surface
## analysis. 

## looking at the tutorials for perspective:
x <- seq(-10, 10, length= 30)
y <- x
f <- function(x, y) { r <- sqrt(x^2+y^2); 10 * sin(r)/r }
z <- outer(x, y, f)
z[is.na(z)] <- 1
op <- par(bg = "white")

persp(x, y, z, theta = 30, phi = 30, expand = 0.5, col = "lightblue")

persp(x, y, z, theta = 30, phi = 30, expand = 0.5, col = "lightblue",
      ltheta = 120, shade = 0.75, ticktype = "detailed",
      xlab = "X", ylab = "Y", zlab = "Sinc( r )"
) -> res
round(res, 3)

x <- 1:10
y <- 1:10
z <- outer(x, y, function(xi, yj) xi^2+yj^2)
persp(x, y, z)

##### apply to our data:

dd <- bb

ee <- dd[order(dd[,"x"],dd[,"y"]),]

order(dd[,"x"])


persp(bb$x, bb$y, bb$fakeDiv)

## ugh, we need an x*y matrix...


## getting ahead of ourselves. We need to build a model before 
## we can display anything.

## this website might be useful
http://www.wekaleamstudios.co.uk/posts/displaying-data-using-level-plots/
## uses loess function to fit a model to a single term x*y model. 

x <- bb$x
y <- bb$y
z <- bb$fakeDiv

bb.loess <- loess(z ~ x*y, degree = 2)

## make our grid. 


range(x)[2] - range(x)[1] ## total range of x is 80,324 m
range(y)[2] - range(y)[1] ## total range of y is 678,639 m

gridA <- expand.grid(list(
    x = seq(range(x)[1],range(x)[2], 5000),
    y = seq(range(y)[1],range(y)[2], 5000)
    ))
z = predict(bb.loess, newdata = gridA)

## perspective tool
persp(
x = seq(range(x)[1],range(x)[2], 5000),
y = seq(range(y)[1],range(y)[2], 5000),
z,
theta = 0, 
phi = 50, 
xlab = "X", ylab = "Y", zlab = "OTU richness",
scale=FALSE
)

## contour tool
library('lattice')
bb.loess$Height = as.numeric(z)
levelplot(Height ~ x*y, data = bb.loess,
  col.regions = terrain.colors(100)
)
## not working...oh well

## try image?
image(x = seq(range(x)[1],range(x)[2], 5000),
y = seq(range(y)[1],range(y)[2], 5000),
z,
xlab = "X Coordinate (feet)", ylab = "Y Coordinate (feet)",
main = "biodiversity", 
#asp=1,
xlim=c(447906,528231)
)

box()

## redo this with graham's data:


## we need to merge our sample data frame with Graham's df. 

library(phyloseq)
library(spatstat)
library(sp)
library(plyr)

grass97m <- import_biom('grass_97_wmeta.biom')
md <- sample_data(grass97m@sam_data)
aa <- md[md$site!="Control",c('host','site','longitude','latitude','fakeDiv')]
aa$longitude <- as.numeric(aa$longitude)
aa$latitude <- as.numeric(aa$latitude)
bb <- ddply(aa, c("site","host"), function(df)c(mean(df$longitude), mean(df$latitude), mean(df$fakeDiv)))
colnames(bb) <- c("site","host", "longitude", "latitude", "fakeDiv")
latlong = SpatialPoints(cbind(bb$longitude, bb$latitude), proj4string=CRS("+proj=longlat"))
UTMs <- spTransform(latlong, CRS("+init=epsg:26910")) ## epsg code for zone 10
UTMs <- data.frame(UTMs) 
bb$x <- UTMs[,1]
bb$y <- UTMs[,2]
bb$longitude <- bb$latitude <- NULL


## we need to average graham's numbers

grRich <- read.csv('rare_richness.csv')
bb <- ddply(aa, c("site","host"), function(df)c(mean(df$longitude), mean(df$latitude), mean(df$fakeDiv)))

grCon <- ddply(grRich, c('site', 'host_species'), function(df)c(mean(df$observations)))

## we need to match some terms for merging
bb$host[bb$host=="D. californica"] <- "Danthonia"
bb$host[bb$host=="F. roemeri"] <- "Festuca"
bb[bb=="French_flat"] <- "French Flat"
bb[bb=="Hazel_Dell"] <- "Hazel Dell"
bb[bb=="Horse_Rock"] <- "Horse Rock"
bb[bb=="Lower_Table"] <- "Lower Table"
bb[bb=="Roxy_Ann"] <- "Roxy Ann"
bb[bb=="Upper_Table"] <- "Upper Table"
bb[bb=="Upper_Weir"] <- "Upper Weir"
colnames(grCon)[2] <- 'host'
colnames(grCon)[3] <- 'observations'

head(bb)
head(grCon)

spRich <- merge(bb, grCon, by = c('site','host'))

## so a plan starts to form...

## basically, we are doing a multiple regression of our z variable
## against all the polynomial terms that are combinations of x and y.
## I think we would make our best guess as to the order of the 
## model, then do some sort of model selection 

#save(spRich, file='spRich.rda')


